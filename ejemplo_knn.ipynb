{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e62c18",
   "metadata": {},
   "source": [
    "# Algoritmo KNN paso a paso\n",
    "Este cuaderno guía el desarrollo de un ejemplo completo del algoritmo *k*-Nearest Neighbors (KNN) en clasificación supervisada. Seguiremos un flujo que incluye la creación del script `ejemplo_knn.py`, la generación y exploración de datos sintéticos, la configuración de hiperparámetros, el entrenamiento documentado línea a línea y el análisis de resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010d3d94",
   "metadata": {},
   "source": [
    "## 1. Configurar dependencias y preparar el script\n",
    "A continuación importamos las bibliotecas que usaremos en el resto del flujo y creamos el archivo `ejemplo_knn.py`. La celda siguiente usa la *magic* `%%writefile` para dejar una estructura mínima sobre la cual iremos añadiendo el código documentado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc5beb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ejemplo_knn.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ejemplo_knn.py\n",
    "\"\"\"Ejemplo completo del algoritmo KNN con documentación paso a paso.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"La lógica principal se completará en secciones posteriores.\"\"\"\n",
    "    raise NotImplementedError(\"El contenido se escribirá en los siguientes pasos del cuaderno.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37561249",
   "metadata": {},
   "source": [
    "**Explicación línea a línea del script generado:**\n",
    "- `\"\"\"Ejemplo completo...\"\"\"` deja un docstring que describe el propósito del programa.\n",
    "- `import numpy as np` importa NumPy para manipular arrays numéricos de forma eficiente.\n",
    "- `import pandas as pd` trae pandas para construir estructuras tabulares y resúmenes.\n",
    "- `from sklearn.datasets import make_classification` habilita la función que crea un dataset sintético para clasificación.\n",
    "- `from sklearn.model_selection import train_test_split` permitirá separar los datos en entrenamiento y prueba.\n",
    "- `from sklearn.preprocessing import StandardScaler` aporta el escalado estándar indispensable en KNN.\n",
    "- `from sklearn.neighbors import KNeighborsClassifier` importa el estimador principal que entrenaremos.\n",
    "- `from sklearn.metrics import accuracy_score, classification_report, confusion_matrix` reúne métricas para evaluar el rendimiento del modelo.\n",
    "- `import matplotlib.pyplot as plt` posibilita visualizaciones y gráficos.\n",
    "- `def main() -> None:` define el punto de entrada; se actualizará con la lógica completa.\n",
    "- `raise NotImplementedError(...)` recuerda que el contenido se completará más adelante en el cuaderno.\n",
    "- `if __name__ == \"__main__\":` asegura la ejecución de `main()` solo cuando el archivo se ejecuta como script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c44474",
   "metadata": {},
   "source": [
    "## 2. Generar datos sintéticos y explorarlos\n",
    "Usaremos `make_classification` para sintetizar ejemplos bidimensionales que permitan visualizar fácilmente las fronteras de decisión de KNN. Las celdas de esta sección muestran cómo se construyen las variables, se resumen las estadísticas y se representa la nube de puntos inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2066dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "feature_names = [\"feature_1\", \"feature_2\"]\n",
    "features, labels = make_classification(\n",
    "    n_samples=400,\n",
    "    n_features=2,\n",
    "    n_redundant=0,\n",
    "    n_informative=2,\n",
    "    n_clusters_per_class=1,\n",
    "    class_sep=1.2,\n",
    "    random_state=SEED,\n",
    ")\n",
    "df = pd.DataFrame(features, columns=feature_names)\n",
    "df[\"target\"] = labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd61fb86",
   "metadata": {},
   "source": [
    "**Detalles de la generación del dataset:**\n",
    "- `SEED = 42` fija una semilla para reproducir los resultados.\n",
    "- `feature_names = [...]` define etiquetas para las columnas numéricas.\n",
    "- `features, labels = make_classification(...` crea 400 observaciones bidimensionales; destaca que `n_redundant=0` evita variables redundantes y `class_sep=1.2` separa clases para un reto moderado.\n",
    "- `random_state=SEED` garantiza la reproducibilidad del muestreo sintético.\n",
    "- `df = pd.DataFrame(...)` transforma los arrays en una tabla pandas con nombres legibles.\n",
    "- `df[\"target\"] = labels` anexa la columna objetivo categórica.\n",
    "- `df.head()` muestra las primeras filas para inspeccionar la estructura resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae49679",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\").transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430fd743",
   "metadata": {},
   "source": [
    "**Resumen estadístico:**\n",
    "- `df.describe(include=\"all\")` calcula estadísticas básicas para cada columna.\n",
    "- `.transpose()` organiza los resultados en filas para facilitar la lectura.\n",
    "- El conteo (`count`) confirma las 400 observaciones; la media (`mean`) y desviación estándar (`std`) muestran la escala de cada rasgo, útil para anticipar la necesidad de escalado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e864576",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "scatter = ax.scatter(\n",
    "    df[\"feature_1\"],\n",
    "    df[\"feature_2\"],\n",
    "    c=df[\"target\"],\n",
    "    cmap=\"coolwarm\",\n",
    "    edgecolor=\"black\",\n",
    "    alpha=0.75,\n",
    ")\n",
    "ax.set_title(\"Distribución inicial de las clases sintetizadas\")\n",
    "ax.set_xlabel(\"feature_1\")\n",
    "ax.set_ylabel(\"feature_2\")\n",
    "legend = ax.legend(*scatter.legend_elements(), title=\"Clase\")\n",
    "ax.add_artist(legend)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2a8f99",
   "metadata": {},
   "source": [
    "**Lectura del gráfico de dispersión:**\n",
    "- `fig, ax = plt.subplots(...)` crea la figura y el eje donde graficaremos.\n",
    "- `ax.scatter(...)` pinta cada observación; `c=df[\"target\"]` colorea según la clase y `edgecolor=\"black\"` mejora el contraste.\n",
    "- `ax.set_title`, `set_xlabel`, `set_ylabel` nombran el gráfico y los ejes.\n",
    "- `ax.legend(*scatter.legend_elements(), ...)` genera una leyenda automáticamente a partir de los valores de la columna objetivo.\n",
    "- `plt.show()` asegura que la figura se renderice en el cuaderno."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32ee7b1",
   "metadata": {},
   "source": [
    "## 3. Dividir datos en entrenamiento y prueba\n",
    "Dividimos el dataset en subconjuntos de entrenamiento y prueba para evaluar el rendimiento del modelo sobre ejemplos no vistos. Escogemos una proporción 80/20 con la misma semilla aleatoria establecida antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1824283",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[feature_names].values\n",
    "y = df[\"target\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=SEED,\n",
    ")\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dfc753",
   "metadata": {},
   "source": [
    "**Desglose de la partición:**\n",
    "- `X = df[feature_names].values` extrae una matriz NumPy con las dos variables predictoras.\n",
    "- `y = df[\"target\"].values` obtiene el vector de etiquetas para entrenamiento supervisado.\n",
    "- `train_test_split(...)` divide los datos: `test_size=0.2` deja 20% para prueba, `stratify=y` mantiene la proporción de clases en cada conjunto y `random_state=SEED` hace reproducible la partición.\n",
    "- `X_train.shape, X_test.shape` confirma las dimensiones de los subconjuntos generados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100a233",
   "metadata": {},
   "source": [
    "## 4. Configurar hiperparámetros del KNN\n",
    "Antes de entrenar debemos normalizar los datos y decidir los hiperparámetros clave del modelo: número de vecinos (`n_neighbors`), esquema de ponderación (`weights`) y métrica de distancia (`metric`). Se incluye una celda para el escalado y otra que fija los valores elegidos justificándolos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1aaaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec1bb6",
   "metadata": {},
   "source": [
    "**Por qué escalamos:**\n",
    "- `scaler = StandardScaler()` instancia el estandarizador que centra la media en 0 y ajusta la desviación estándar a 1.\n",
    "- `scaler.fit_transform(X_train)` aprende la media y desviación a partir del conjunto de entrenamiento y transforma los datos.\n",
    "- `scaler.transform(X_test)` aplica la misma transformación al conjunto de prueba sin recalcular parámetros para evitar fuga de información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdefde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\n",
    "    \"n_neighbors\": 5,\n",
    "    \"weights\": \"distance\",\n",
    "    \"metric\": \"minkowski\",\n",
    "    \"p\": 2,\n",
    "    \"algorithm\": \"auto\",\n",
    "    \"leaf_size\": 30,\n",
    "}\n",
    "knn_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866cc17f",
   "metadata": {},
   "source": [
    "**Justificación de los hiperparámetros:**\n",
    "- `n_neighbors=5` promedia la información de cinco vecinos, suavizando el contorno de decisión y equilibrando sesgo-varianza.\n",
    "- `weights=\"distance\"` da más peso a los vecinos más cercanos para reducir decisiones ruidosas en zonas mixtas.\n",
    "- `metric=\"minkowski\"` junto con `p=2` equivale a la distancia euclidiana clásica; permite cambiar a Manhattan (`p=1`) si fuera necesario.\n",
    "- `algorithm=\"auto\"` deja que scikit-learn elija la estrategia de búsqueda más eficiente según el tamaño del dataset.\n",
    "- `leaf_size=30` controla el tamaño de los nodos en estructuras KDTree/BallTree; su valor por defecto funciona bien para datasets medianos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f10283",
   "metadata": {},
   "source": [
    "## 5. Implementar y documentar el entrenamiento KNN línea a línea\n",
    "Reescribimos `ejemplo_knn.py` incorporando toda la lógica del pipeline con comentarios que detallan cada instrucción. La estructura reproduce las etapas vistas en las secciones anteriores para que el script pueda ejecutarse de forma autónoma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ejemplo_knn.py\n",
    "\"\"\"Ejemplo completo del algoritmo KNN con documentación paso a paso.\"\"\"\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SEED = 42\n",
    "FEATURE_NAMES = [\"feature_1\", \"feature_2\"]\n",
    "\n",
    "\n",
    "def build_dataset(seed: int) -> pd.DataFrame:\n",
    "    \"\"\"Genera un dataset sintético reproducible con dos características informativas.\"\"\"\n",
    "    # Generamos la matriz de características y el vector objetivo usando make_classification.\n",
    "    features, labels = make_classification(\n",
    "        n_samples=400,\n",
    "        n_features=2,\n",
    "        n_redundant=0,\n",
    "        n_informative=2,\n",
    "        n_clusters_per_class=1,\n",
    "        class_sep=1.2,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    # Convertimos las características en un DataFrame con nombres amigables.\n",
    "    df = pd.DataFrame(features, columns=FEATURE_NAMES)\n",
    "    # Añadimos la columna objetivo con las etiquetas de clase.\n",
    "    df[\"target\"] = labels\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_dataset(\n",
    "    df: pd.DataFrame, seed: int\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Divide el dataset en entrenamiento y prueba conservando la proporción de clases.\"\"\"\n",
    "    # Separamos las columnas predictoras de la columna objetivo.\n",
    "    X = df[FEATURE_NAMES].values\n",
    "    y = df[\"target\"].values\n",
    "    # Realizamos la partición estratificada para mantener el balance de clases.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        stratify=y,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def scale_features(\n",
    "    X_train: np.ndarray, X_test: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray, StandardScaler]:\n",
    "    \"\"\"Escala los subconjuntos con StandardScaler y devuelve el objeto entrenado.\"\"\"\n",
    "    # Instanciamos el estandarizador para centrar y escalar las variables.\n",
    "    scaler = StandardScaler()\n",
    "    # Ajustamos el escalador usando solo el conjunto de entrenamiento y transformamos los valores.\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    # Aplicamos la misma transformación a los datos de prueba.\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled, scaler\n",
    "\n",
    "\n",
    "def instantiate_model(params: Dict[str, object]) -> KNeighborsClassifier:\n",
    "    \"\"\"Crea el clasificador KNN con los hiperparámetros indicados.\"\"\"\n",
    "    # Construimos el estimador pasando el diccionario de hiperparámetros con desempaquetado.\n",
    "    model = KNeighborsClassifier(**params)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model: KNeighborsClassifier, X_train: np.ndarray, y_train: np.ndarray\n",
    ") -> KNeighborsClassifier:\n",
    "    \"\"\"Ajusta el modelo KNN y devuelve la instancia entrenada.\"\"\"\n",
    "    # Llamamos a fit para almacenar los ejemplos de entrenamiento en la estructura interna del modelo.\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model: KNeighborsClassifier,\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    ") -> Tuple[float, float, str, np.ndarray]:\n",
    "    \"\"\"Calcula métricas de rendimiento sobre entrenamiento y prueba.\"\"\"\n",
    "    # Generamos predicciones sobre el conjunto de entrenamiento para medir sobreajuste potencial.\n",
    "    train_predictions = model.predict(X_train)\n",
    "    # Generamos predicciones sobre el conjunto de prueba para estimar generalización.\n",
    "    test_predictions = model.predict(X_test)\n",
    "    # Calculamos la exactitud en entrenamiento como referencia.\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    # Calculamos la exactitud en prueba para medir el desempeño real.\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    # Producimos un informe detallado con precisión, recall y f1-score por clase.\n",
    "    detailed_report = classification_report(y_test, test_predictions)\n",
    "    # Construimos la matriz de confusión para analizar aciertos y errores por clase.\n",
    "    confusion = confusion_matrix(y_test, test_predictions)\n",
    "    return train_accuracy, test_accuracy, detailed_report, confusion\n",
    "\n",
    "\n",
    "def plot_decision_boundary(\n",
    "    model: KNeighborsClassifier,\n",
    "    scaler: StandardScaler,\n",
    "    df: pd.DataFrame,\n",
    ") -> None:\n",
    "    \"\"\"Grafica la frontera de decisión aprendida.\"\"\"\n",
    "    # Determinamos los límites del plano añadiendo un margen alrededor de los datos.\n",
    "    x_min, x_max = df[\"feature_1\"].min() - 0.5, df[\"feature_1\"].max() + 0.5\n",
    "    y_min, y_max = df[\"feature_2\"].min() - 0.5, df[\"feature_2\"].max() + 0.5\n",
    "    # Creamos una malla regular con paso fino para evaluar las predicciones del modelo.\n",
    "    grid_x, grid_y = np.meshgrid(\n",
    "        np.linspace(x_min, x_max, 300),\n",
    "        np.linspace(y_min, y_max, 300),\n",
    "    )\n",
    "    # Reorganizamos la malla en una matriz de coordenadas y la escalamos con los parámetros aprendidos.\n",
    "    grid_points = np.c_[grid_x.ravel(), grid_y.ravel()]\n",
    "    grid_points_scaled = scaler.transform(grid_points)\n",
    "    # Calculamos las predicciones del modelo sobre cada punto de la malla.\n",
    "    grid_predictions = model.predict(grid_points_scaled).reshape(grid_x.shape)\n",
    "    # Definimos un mapa de colores suave para representar las clases.\n",
    "    cmap = ListedColormap([\"#ff9999\", \"#99ccff\"])\n",
    "    # Construimos la figura y el eje para el gráfico de frontera.\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    # Pintamos la superficie con las predicciones usando contourf.\n",
    "    ax.contourf(grid_x, grid_y, grid_predictions, alpha=0.4, cmap=cmap)\n",
    "    # Dibujamos los puntos reales por encima para comparar con la frontera.\n",
    "    scatter = ax.scatter(\n",
    "        df[\"feature_1\"],\n",
    "        df[\"feature_2\"],\n",
    "        c=df[\"target\"],\n",
    "        cmap=\"coolwarm\",\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.75,\n",
    "    )\n",
    "    # Añadimos título y etiquetas descriptivas a los ejes.\n",
    "    ax.set_title(\"Frontera de decisión estimada por KNN\")\n",
    "    ax.set_xlabel(\"feature_1\")\n",
    "    ax.set_ylabel(\"feature_2\")\n",
    "    # Creamos la leyenda derivada de los elementos del diagrama de dispersión.\n",
    "    legend = ax.legend(*scatter.legend_elements(), title=\"Clase\")\n",
    "    ax.add_artist(legend)\n",
    "    # Mostramos el gráfico en pantalla.\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Ejecuta el flujo completo de entrenamiento, evaluación y visualización.\"\"\"\n",
    "    # Fijamos la semilla de NumPy para reproducir cualquier operación aleatoria adicional.\n",
    "    np.random.seed(SEED)\n",
    "    # Construimos el dataset sintético que se usará durante todo el flujo.\n",
    "    dataset = build_dataset(seed=SEED)\n",
    "    # Dividimos el dataset en subconjuntos de entrenamiento y prueba.\n",
    "    X_train, X_test, y_train, y_test = split_dataset(dataset, seed=SEED)\n",
    "    # Escalamos los subconjuntos obteniendo también el escalador entrenado.\n",
    "    X_train_scaled, X_test_scaled, scaler = scale_features(X_train, X_test)\n",
    "    # Definimos los hiperparámetros que regirán las predicciones del modelo KNN.\n",
    "    params = {\n",
    "        \"n_neighbors\": 5,\n",
    "        \"weights\": \"distance\",\n",
    "        \"metric\": \"minkowski\",\n",
    "        \"p\": 2,\n",
    "        \"algorithm\": \"auto\",\n",
    "        \"leaf_size\": 30,\n",
    "    }\n",
    "    # Creamos el clasificador KNN con los hiperparámetros seleccionados.\n",
    "    knn = instantiate_model(params)\n",
    "    # Ajustamos el clasificador usando los datos escalados de entrenamiento.\n",
    "    knn = train_model(knn, X_train_scaled, y_train)\n",
    "    # Evaluamos el rendimiento tanto en entrenamiento como en prueba.\n",
    "    train_acc, test_acc, report, confusion = evaluate_model(\n",
    "        knn,\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        X_test_scaled,\n",
    "        y_test,\n",
    "    )\n",
    "    # Mostramos la métrica de exactitud en consola para comparar ambos conjuntos.\n",
    "    print(f\"Exactitud entrenamiento: {train_acc:.3f}\")\n",
    "    print(f\"Exactitud prueba: {test_acc:.3f}\")\n",
    "    # Presentamos el informe detallado con precisión, recall y f1-score.\n",
    "    print(\"\\nInforme de clasificación:\\n\" + report)\n",
    "    # Imprimimos la matriz de confusión para analizar errores específicos.\n",
    "    print(\"Matriz de confusión:\\n\", confusion)\n",
    "    # Visualizamos la frontera de decisión obtenida por el modelo entrenado.\n",
    "    plot_decision_boundary(knn, scaler, dataset)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d68a00",
   "metadata": {},
   "source": [
    "**Puntos clave del script actualizado:**\n",
    "- `build_dataset` encapsula la creación del dataset sintético con comentarios que justifican cada parámetro de `make_classification`.\n",
    "- `split_dataset` y `scale_features` separan y estandarizan los datos asegurando reproducibilidad (`random_state=SEED`).\n",
    "- `instantiate_model` y `train_model` muestran explícitamente cómo se construye y ajusta el clasificador usando el diccionario `params`.\n",
    "- `evaluate_model` calcula exactitud, reporte y matriz de confusión explicando el motivo de cada línea.\n",
    "- `plot_decision_boundary` crea la malla, transforma los puntos con el `StandardScaler` y visualiza la frontera aprendida.\n",
    "- `main` orquesta el flujo completo imprimiendo métricas y llamando a la función de visualización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28da1ae2",
   "metadata": {},
   "source": [
    "## 6. Evaluar el modelo con métricas detalladas\n",
    "Ejecutamos las funciones creadas para entrenar el modelo en el entorno interactivo y analizamos métricas como exactitud, matriz de confusión e informe de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e2adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "knn_model = KNeighborsClassifier(**knn_params)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "train_predictions = knn_model.predict(X_train_scaled)\n",
    "test_predictions = knn_model.predict(X_test_scaled)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(f\"Exactitud entrenamiento: {train_accuracy:.3f}\")\n",
    "print(f\"Exactitud prueba: {test_accuracy:.3f}\")\n",
    "print(\"\\nInforme de clasificación:\\n\", classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c117027",
   "metadata": {},
   "source": [
    "**Interpretación de la celda anterior:**\n",
    "- `from sklearn.metrics import ConfusionMatrixDisplay` habilita la visualización matricial que emplearemos luego.\n",
    "- `knn_model = KNeighborsClassifier(**knn_params)` recrea el clasificador con los hiperparámetros discutidos.\n",
    "- `fit`, `predict` sobre entrenamiento y prueba calculan las etiquetas estimadas para evaluar rendimiento y sobreajuste.\n",
    "- `accuracy_score` ofrece la exactitud en ambos subconjuntos; comparar ambas cifras ayuda a detectar overfitting.\n",
    "- `classification_report(...)` genera precisión, recall y f1 por clase, útil para diagnosticar desbalanceos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8524aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, test_predictions)\n",
    "ConfusionMatrixDisplay(cm).plot(cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4556db",
   "metadata": {},
   "source": [
    "**Lectura de la matriz de confusión:**\n",
    "- `confusion_matrix(y_test, test_predictions)` cruza las clases reales y predichas.\n",
    "- `ConfusionMatrixDisplay(cm).plot(...)` dibuja la matriz en escala de azules para resaltar aciertos y errores.\n",
    "- `plt.show()` asegura que la figura se renderice al ejecutar el cuaderno."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ed0758",
   "metadata": {},
   "source": [
    "## 7. Visualizar fronteras de decisión y análisis final\n",
    "Para comprender la influencia de los hiperparámetros graficamos la frontera de decisión del modelo y debatimos cómo afecta cada elección sobre el comportamiento observado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0dbb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import ejemplo_knn\n",
    "\n",
    "importlib.reload(ejemplo_knn)\n",
    "ejemplo_knn.plot_decision_boundary(knn_model, scaler, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed60966",
   "metadata": {},
   "source": [
    "**Análisis de la frontera de decisión:**\n",
    "- `importlib.reload(ejemplo_knn)` garantiza que usemos la versión del script generada en esta sesión.\n",
    "- `plot_decision_boundary(knn_model, scaler, df)` aplica el escalador aprendido a la malla de puntos y dibuja la clasificación que produce el modelo entrenado.\n",
    "- El contorno resultante muestra regiones suaves gracias a `n_neighbors=5`; un valor menor generaría fronteras más irregulares, mientras que uno mayor las haría demasiado lisas.\n",
    "- El esquema `weights=\"distance\"` provoca transiciones más graduales cerca de los límites porque otorga más influencia a los vecinos inmediatos.\n",
    "- Cambiar `metric` a Manhattan (`p=1`) inclinaría las fronteras hacia líneas con ángulos rectos, evidenciando la importancia de este hiperparámetro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1d864f",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "El pipeline demuestra cómo cada hiperparámetro de KNN influye en la frontera de decisión y en las métricas finales. El script `ejemplo_knn.py` queda listo para ejecutarse de forma independiente, reproduciendo los pasos explicados en el cuaderno y facilitando la experimentación con distintos valores de `n_neighbors`, `weights` y `metric`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nuevo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
